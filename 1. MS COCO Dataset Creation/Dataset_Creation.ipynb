{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuP1VJ5fhZPPGH/DF07z6D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/copyrightFreeGenAI/copyrightFreeImagesGenAI/blob/main/1.%20MS%20COCO%20Dataset%20Creation/Dataset_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create MS COCO Dataset**"
      ],
      "metadata": {
        "id": "KjYp7uw54W3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Paths for Fine-tuning Dataset\n",
        "annTrainInstanceFiles = \"/content/gdrive/MyDrive/annotations2014/instances_val2014.json\" # Path to validation instance json, download from MS COCO\n",
        "annTrainCaptionFiles = \"/content/gdrive/MyDrive/annotations2014/captions_val2014.json\" # Path to validation caption json, download from MS COCO\n",
        "train_ranking_directory = \"/content/gdrive/MyDrive/DATA/COCO/Fine-Tuning/Rankings\" # Path to directory where rankings will be saved\n",
        "train_images_directory = \"/content/gdrive/MyDrive/DATA/COCO/Fine-Tuning/Images\" # Path to directory where images will be saved\n",
        "\n",
        "# Set Paths for Benchmark Dataset\n",
        "annValInstanceFiles = \"/content/gdrive/MyDrive/annotations2014/instances_train2014.json\" # Path to train instance json, download from MS COCO\n",
        "annValCaptionFiles = \"/content/gdrive/MyDrive/annotations2014/captions_train2014.json\" # Path to train caption json, download from MS COCO\n",
        "val_ranking_directory = \"/content/gdrive/MyDrive/DATA/COCO/Validation/Rankings\"  # Path to directory where rankings will be save\n",
        "val_images_directory = \"/content/gdrive/MyDrive/DATA/COCO/Validation/Images\" # Path to directory where images will be saved"
      ],
      "metadata": {
        "id": "smNV8FB097tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "QQxfam0S9kyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "c91LpKWZ9n1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import skimage.io as io\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16  import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from tensorflow.image import resize\n",
        "import spacy"
      ],
      "metadata": {
        "id": "4lct7dDM9oJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(weights='imagenet')\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "y60brpV_9zJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning Dataset"
      ],
      "metadata": {
        "id": "nxS6Hf4a8z6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco=COCO(annTrainInstanceFiles)\n",
        "coco_caps=COCO(annTrainCaptionFiles)\n",
        "cats = coco.loadCats(coco.getCatIds())"
      ],
      "metadata": {
        "id": "orHsJPe_9aos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Fine-tuning Rankings"
      ],
      "metadata": {
        "id": "rZspxvlVCp78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in cats:\n",
        "    # Skip categories that don't have enough good quality images\n",
        "    if cat['name'] in ['handbag', 'sports ball', 'toaster', 'hair drier']:\n",
        "        continue\n",
        "\n",
        "    print(cat['name'])  # Log current category being processed\n",
        "\n",
        "    area_dic = {}  # Dictionary to store object area relative to image size\n",
        "    nlp_dic = {}   # Dictionary to store semantic relevance scores\n",
        "    dic = {}       # Unused dictionary (could consider removing if not needed)\n",
        "\n",
        "    category = nlp(cat['name'])  # Parse category name with NLP model\n",
        "\n",
        "    # Get image IDs that contain this category\n",
        "    catIds = coco.getCatIds(catNms=[cat['name']])\n",
        "    imgIds = coco.getImgIds(catIds=catIds)\n",
        "\n",
        "    # Create a folder to store results for this category\n",
        "    folder_path = os.path.join(train_ranking_directory, cat['name'])\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    for i in range(min(len(imgIds), 10000)):  # Limit to 10,000 images max\n",
        "        quality = 0  # Initialize quality score\n",
        "\n",
        "        img = coco.loadImgs(imgIds[i])[0]\n",
        "        img_url = img['coco_url']\n",
        "\n",
        "        # Load captions for the image\n",
        "        annIds = coco_caps.getAnnIds(imgIds=img['id'])\n",
        "        anns = coco_caps.loadAnns(annIds)\n",
        "        captions_list = [item['caption'].lower() for item in anns]\n",
        "        prompt = ' '.join(captions_list)\n",
        "\n",
        "        # Skip if the category name is not mentioned in the captions\n",
        "        if cat['name'] not in prompt:\n",
        "            continue\n",
        "\n",
        "        I = io.imread(img_url)  # Load image from URL\n",
        "\n",
        "        try:\n",
        "            # Resize image and calculate object area ratio\n",
        "            resized_image = resize(I, (224, 224)).numpy()\n",
        "            annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
        "            anns = coco.loadAnns(annIds)\n",
        "            area = anns[0]['area'] / (img['height'] * img['width'])\n",
        "            area_dic[i] = area\n",
        "        except:\n",
        "            continue  # Skip image if resizing or annotation fails\n",
        "\n",
        "        # Preprocess image for model prediction\n",
        "        preprocessed_image = preprocess_input(np.expand_dims(resized_image, axis=0))\n",
        "        predictions = model.predict(preprocessed_image)\n",
        "        decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
        "\n",
        "        # Compute NLP similarity between predicted labels and category\n",
        "        for j, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
        "            label = label.replace(\"_\", \" \")\n",
        "            word = nlp(label)\n",
        "            quality += category.similarity(word) * score\n",
        "\n",
        "        nlp_dic[i] = quality  # Store total quality score for the image\n",
        "\n",
        "    # Save results to JSON files\n",
        "    with open(os.path.join(folder_path, f\"area_{cat['name']}.json\"), 'w') as json_file:\n",
        "        json.dump(area_dic, json_file)\n",
        "\n",
        "    with open(os.path.join(folder_path, f\"nlp_{cat['name']}.json\"), 'w') as json_file:\n",
        "        json.dump(nlp_dic, json_file)"
      ],
      "metadata": {
        "id": "TattFyS0CpXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve Top 20 Images per Category based on Ranking"
      ],
      "metadata": {
        "id": "7k1_7iurDEK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in cats:\n",
        "    if cat['name'] in ['handbag', 'sports ball', 'toaster', 'hair drier']:\n",
        "      continue\n",
        "    print(cat['name'])\n",
        "    area_file = os.path.join(train_ranking_directory, cat['name'], \"area_\" + cat['name'] + \".json\")\n",
        "    nlp_file = os.path.join(train_ranking_directory, cat['name'], \"nlp_\" + cat['name'] + \".json\")\n",
        "\n",
        "    # Prepare to save images\n",
        "    save_dir = os.path.join(train_images_directory, cat['name'])\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Load area and NLP data\n",
        "    with open(area_file, 'r') as file:\n",
        "        area = json.load(file)\n",
        "    with open(nlp_file, 'r') as file:\n",
        "        nlp = json.load(file)\n",
        "\n",
        "    # Normalize area\n",
        "    min_area = min(area.values())\n",
        "    max_area = max(area.values())\n",
        "    normalized_area = {key: (value - min_area) / (max_area - min_area) for key, value in area.items()}\n",
        "\n",
        "    # Normalize nlp\n",
        "    min_nlp = min(nlp.values())\n",
        "    max_nlp = max(nlp.values())\n",
        "    normalized_nlp = {key: (value - min_nlp) / (max_nlp - min_nlp) for key, value in nlp.items()}\n",
        "\n",
        "    # Calculate scores using normalized values\n",
        "    scores = {key: 0.5 * normalized_area[key] + 0.5 * normalized_nlp[key] for key in area}\n",
        "\n",
        "    # Get the top 20 scores\n",
        "    top_20 = sorted(scores.items(), key=lambda item: item[1], reverse=True)[:20]\n",
        "\n",
        "    # Get category and image IDs\n",
        "    catIds = coco.getCatIds(catNms=[cat['name']])\n",
        "    imgIds = coco.getImgIds(catIds=catIds)\n",
        "\n",
        "    # Save the top 20 images\n",
        "    for key, _ in top_20:\n",
        "        img_index = int(key)\n",
        "        if img_index < len(imgIds):\n",
        "            img = coco.loadImgs(imgIds[img_index])[0]\n",
        "            img_url = img['coco_url']\n",
        "            I = io.imread(img_url)\n",
        "            file_path = os.path.join(save_dir, f\"{key}.jpg\")\n",
        "            io.imsave(file_path, I)\n",
        "        else:\n",
        "            print(f\"Warning: Key {key} does not correspond to a valid imgId.\")"
      ],
      "metadata": {
        "id": "POfnpnb0De1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark Dataset"
      ],
      "metadata": {
        "id": "b88qL4JE85BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco=COCO(annTrainInstanceFiles)\n",
        "coco_caps=COCO(annTrainCaptionFiles)\n",
        "cats = coco.loadCats(coco.getCatIds())"
      ],
      "metadata": {
        "id": "VyIMDNLn3gES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Benchmark Rankings"
      ],
      "metadata": {
        "id": "tDaxpxoo6Uqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in cats:\n",
        "    # Skip categories lacking sufficient good quality images\n",
        "    if cat['name'] in ['handbag', 'sports ball', 'toaster', 'hair drier']:\n",
        "        continue\n",
        "\n",
        "    print(cat['name'])  # Log current category being processed\n",
        "\n",
        "    area_dic = {}  # To store normalized object area per image\n",
        "    nlp_dic = {}   # To store semantic similarity quality scores\n",
        "    dic = {}       # (Unused dictionary—can be removed if unnecessary)\n",
        "\n",
        "    category = nlp(cat['name'])  # Process category name with NLP model\n",
        "\n",
        "    # Get image IDs associated with this category\n",
        "    catIds = coco.getCatIds(catNms=[cat['name']])\n",
        "    imgIds = coco.getImgIds(catIds=catIds)\n",
        "\n",
        "    # Create output directory for results\n",
        "    folder_path = os.path.join(val_ranking_directory, cat['name'])\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    for i in range(min(len(imgIds), 10000)):  # Limit to 10,000 images\n",
        "        quality = 0\n",
        "\n",
        "        img = coco.loadImgs(imgIds[i])[0]\n",
        "        img_url = img['coco_url']\n",
        "\n",
        "        # Get all captions for the image\n",
        "        annIds = coco_caps.getAnnIds(imgIds=img['id'])\n",
        "        anns = coco_caps.loadAnns(annIds)\n",
        "        captions_list = [item['caption'].lower() for item in anns]\n",
        "        prompt = ' '.join(captions_list)\n",
        "\n",
        "        # Skip images where captions don’t mention the category\n",
        "        if cat['name'] not in prompt:\n",
        "            continue\n",
        "\n",
        "        I = io.imread(img_url)\n",
        "\n",
        "        try:\n",
        "            # Resize image and compute area of annotated object\n",
        "            resized_image = resize(I, (224, 224)).numpy()\n",
        "            annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
        "            anns = coco.loadAnns(annIds)\n",
        "            area = anns[0]['area'] / (img['height'] * img['width'])\n",
        "            area_dic[i] = area\n",
        "        except:\n",
        "            continue  # Skip if image or annotation processing fails\n",
        "\n",
        "        # Run image through prediction model\n",
        "        preprocessed_image = preprocess_input(np.expand_dims(resized_image, axis=0))\n",
        "        predictions = model.predict(preprocessed_image)\n",
        "        decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
        "\n",
        "        # Score image by NLP similarity between predicted labels and category\n",
        "        for j, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
        "            label = label.replace(\"_\", \" \")\n",
        "            word = nlp(label)\n",
        "            quality += category.similarity(word) * score\n",
        "\n",
        "        nlp_dic[i] = quality\n",
        "\n",
        "    # Save results for this category\n",
        "    with open(os.path.join(folder_path, f\"area_{cat['name']}.json\"), 'w') as json_file:\n",
        "        json.dump(area_dic, json_file)\n",
        "\n",
        "    with open(os.path.join(folder_path, f\"nlp_{cat['name']}.json\"), 'w') as json_file:\n",
        "        json.dump(nlp_dic, json_file)"
      ],
      "metadata": {
        "id": "13ug2GSz6O2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve Top 100 Images per Category based on Ranking"
      ],
      "metadata": {
        "id": "qg_DtpCW6o-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in cats:\n",
        "    # Skip categories lacking sufficient good quality images\n",
        "    if cat['name'] in ['handbag', 'sports ball', 'toaster', 'hair drier']:\n",
        "        continue\n",
        "    print(cat['name'])\n",
        "    area_file = os.path.join(val_ranking_directory, cat['name'], \"area_\" + cat['name'] + \".json\")\n",
        "    nlp_file = os.path.join(val_ranking_directory, cat['name'], \"nlp_\" + cat['name'] + \".json\")\n",
        "\n",
        "    # Load area and NLP data\n",
        "    with open(area_file, 'r') as file:\n",
        "        area = json.load(file)\n",
        "    with open(nlp_file, 'r') as file:\n",
        "        nlp = json.load(file)\n",
        "\n",
        "    # Normalize area\n",
        "    min_area = min(area.values())\n",
        "    max_area = max(area.values())\n",
        "    normalized_area = {key: (value - min_area) / (max_area - min_area) for key, value in area.items()}\n",
        "\n",
        "    # Normalize nlp\n",
        "    min_nlp = min(nlp.values())\n",
        "    max_nlp = max(nlp.values())\n",
        "    normalized_nlp = {key: (value - min_nlp) / (max_nlp - min_nlp) for key, value in nlp.items()}\n",
        "\n",
        "    # Calculate scores using normalized values\n",
        "    scores = {key: 0.5 * normalized_area[key] + 0.5 * normalized_nlp[key] for key in area}\n",
        "\n",
        "    # Get the top 100 scores\n",
        "    top_100 = sorted(scores.items(), key=lambda item: item[1], reverse=True)[:100]\n",
        "\n",
        "    # Prepare to save images\n",
        "    save_dir = os.path.join(val_images_directory, cat['name'])\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Get category and image IDs\n",
        "    catIds = coco.getCatIds(catNms=[cat['name']])\n",
        "    imgIds = coco.getImgIds(catIds=catIds)\n",
        "\n",
        "    # Save the top 100 images\n",
        "    for key, _ in top_100:\n",
        "        img_index = int(key)\n",
        "        if img_index < len(imgIds):\n",
        "            img = coco.loadImgs(imgIds[img_index])[0]\n",
        "            img_url = img['coco_url']\n",
        "            I = io.imread(img_url)\n",
        "            file_path = os.path.join(save_dir, f\"{key}.jpg\")\n",
        "            io.imsave(file_path, I)\n",
        "        else:\n",
        "            print(f\"Warning: Key {key} does not correspond to a valid imgId.\")"
      ],
      "metadata": {
        "id": "SYEF85H86nEw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}