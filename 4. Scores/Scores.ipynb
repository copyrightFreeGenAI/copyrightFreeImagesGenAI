{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMWuAEOxZtwcQVLGcvj1Cw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/copyrightFreeGenAI/copyrightFreeImagesGenAI/blob/main/4.%20Scores/Scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRGrN-4BmJfq"
      },
      "outputs": [],
      "source": [
        "# Set Paths\n",
        "annValInstanceFiles = \"/content/gdrive/MyDrive/annotations2014/instances_train2014.json\" # Path to benchmark instance json\n",
        "annValCaptionFiles = \"/content/gdrive/MyDrive/annotations2014/captions_train2014.json\" # Path to benchmark caption json\n",
        "source_directory = \"/content/gdrive/MyDrive/DATA/COCO/Validation/Images\" # Path to directory where benchmark MS COCO images are saved\n",
        "\n",
        "mitsua_target_directory = \"/content/gdrive/MyDrive//DATA/Mitsua/\" # Path to directory where Mitsua images are saved\n",
        "sd21_target_directory = \"/content/gdrive/MyDrive/DATA/SD2.1/\" # Path to directory where SD2.1 images are saved\n",
        "juggxl_target_directory = \"/content/gdrive/MyDrive/DATA/JuggXL/\" # Path to directory where JuggXL images are saved\n",
        "dalle2_target_directory = \"/content/gdrive/MyDrive/DATA/Dalle2/\" # Path to directory where Dall-E-2 images are saved\n",
        "DREAM_target_directory = \"/content/gdrive/MyDrive/Dream/Dream/\" # Path where DreamBooth images are saved\n",
        "LORA_target_directory = \"/content/gdrive/MyDrive/LoRA/LoRA/\" # Path where LoRA images are saved\n",
        "TI_target_directory = \"/content/gdrive/MyDrive/Textual-Inversion/Textual-Inversion/Images/\" # Path where TI images are saved\n",
        "\n",
        "baseline_scores_directory = \"/content/gdrive/MyDrive/Scores/Scores/baseline.csv\" # Path to store scores for baseline models\n",
        "finetuned_scores_directory = \"/content/gdrive/MyDrive/Scores/Scores/finetuned.csv\" # Path to store fine-tuned scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "3geutRy2a05v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from io import BytesIO\n",
        "from numpy.linalg import svd\n",
        "from skimage.transform import resize\n",
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.linalg import sqrtm"
      ],
      "metadata": {
        "id": "bHfEOQFxa8Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco=COCO(annValInstanceFiles)\n",
        "coco_caps=COCO(annValCaptionFiles)\n",
        "cats = coco.loadCats(coco.getCatIds())"
      ],
      "metadata": {
        "id": "8QbM8u4lbPkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fid_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "id": "dM0IHKyqa9Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate frechet inception distance\n",
        "def calculate_fid(model, images1, images2):\n",
        "\t# calculate activations\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid"
      ],
      "metadata": {
        "id": "iECh7wCya94L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_clip(clip, processor, prompt, image):\n",
        "    clip_scores = []\n",
        "    img = []\n",
        "    for i in image:\n",
        "        if i.min() < 0:\n",
        "            img.append((i + 1) / 2)\n",
        "        else:\n",
        "            img.append(i)\n",
        "    # Move the CLIP model to the appropriate device (GPU if available)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    clip = clip.to(device)\n",
        "\n",
        "    for i in range(len(img)):\n",
        "        inputs = processor(text=prompt[i], images=img[i], return_tensors=\"pt\", padding=True)\n",
        "        # Move the input tensors to the same device as the model\n",
        "        inputs = inputs.to(device)\n",
        "        # Compute the embeddings\n",
        "        outputs = clip(**inputs)\n",
        "        image_embeddings = outputs.image_embeds\n",
        "        text_embeddings = outputs.text_embeds\n",
        "        # Calculate the cosine similarity\n",
        "        similarity = torch.nn.functional.cosine_similarity(image_embeddings, text_embeddings)\n",
        "        # The similarity score\n",
        "        clip_scores.append(np.mean(similarity.tolist()))\n",
        "    return 100 * np.mean(clip_scores)"
      ],
      "metadata": {
        "id": "QrQ9ZPo9bFbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        " images_list = list()\n",
        " for image in images:\n",
        "   image = np.array(image)\n",
        "   # resize with nearest neighbor interpolation\n",
        "   new_image = resize(image, new_shape)\n",
        "   # store\n",
        "   images_list.append(new_image)\n",
        " return asarray(images_list)"
      ],
      "metadata": {
        "id": "oikPK3O4bGsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_directory(directory):\n",
        "    image_list = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img = Image.open(img_path)\n",
        "            img_array = np.array(img)\n",
        "            image_list.append(img_array)\n",
        "    return image_list"
      ],
      "metadata": {
        "id": "4To9eP4ubS6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_base = []\n",
        "row_fine = []\n",
        "\n",
        "for cat in cats:\n",
        "    print(cat['name'])\n",
        "    if not os.path.exists(os.path.join(source_directory, cat[\"name\"])):\n",
        "        continue\n",
        "    catIds = coco.getCatIds(catNms=[cat['name']])\n",
        "    imgIds = coco.getImgIds(catIds=catIds)\n",
        "    filenames = os.listdir(os.path.join(source_directory, cat[\"name\"]))\n",
        "    names_before_dot = [int(os.path.splitext(file)[0]) for file in filenames]\n",
        "    og = []\n",
        "    prompt = []\n",
        "    for image_id in names_before_dot:\n",
        "        og_path = os.path.join(os.path.join(source_directory, cat[\"name\"]), str(image_id) + \".jpg\")\n",
        "        img = coco.loadImgs(imgIds[image_id])[0]\n",
        "        I = io.imread(og_path)\n",
        "        if I.ndim == 2:  # If the image is grayscale, convert to RGB\n",
        "            I = np.stack((I,) * 3, axis=-1)\n",
        "        og.append(I)\n",
        "        annIds = coco_caps.getAnnIds(imgIds=img['id'])\n",
        "        anns = coco_caps.loadAnns(annIds)\n",
        "        captions_list = [item['caption'] for item in anns]\n",
        "        prompt.append(captions_list)\n",
        "\n",
        "    # baseline\n",
        "    Mitsua = load_images_from_directory(mitsua_target_directory + cat['name'])\n",
        "    SD21 = load_images_from_directory(sd21_target_directory + cat['name'])\n",
        "    JUGGXL = load_images_from_directory(juggxl_target_directory + cat['name'])\n",
        "    DALLE2 = load_images_from_directory(dalle2_target_directory + cat['name'])\n",
        "    # Fine-tune\n",
        "    DREAM = load_images_from_directory(DREAM_target_directory + cat['name'])\n",
        "    LORA = load_images_from_directory(LORA_target_directory + cat['name'])\n",
        "    TI = load_images_from_directory(TI_target_directory + cat['name'])\n",
        "\n",
        "    image_og = scale_images(og, (299, 299, 3))\n",
        "    image_og = preprocess_input(image_og)\n",
        "    image_MITSUA = scale_images(Mitsua, (299, 299, 3))\n",
        "    image_MITSUA = preprocess_input(image_MITSUA)\n",
        "    image_SD21 = scale_images(SD21, (299, 299, 3))\n",
        "    image_SD21 = preprocess_input(image_SD21)\n",
        "    image_JUGGXL = scale_images(JUGGXL, (299, 299, 3))\n",
        "    image_JUGGXL = preprocess_input(image_JUGGXL)\n",
        "    image_DALLE2 = scale_images(DALLE2, (299, 299, 3))\n",
        "    image_DALLE2 = preprocess_input(image_DALLE2)\n",
        "    image_DREAM = scale_images(DREAM, (299, 299, 3))\n",
        "    image_DREAM = preprocess_input(image_DREAM)\n",
        "    image_LORA = scale_images(LORA, (299, 299, 3))\n",
        "    image_LORA = preprocess_input(image_LORA)\n",
        "    image_TI = scale_images(TI, (299, 299, 3))\n",
        "    image_TI = preprocess_input(image_TI)\n",
        "\n",
        "    clip_score_og = calculate_clip(clip, clip_processor, prompt, image_og)\n",
        "    clip_score_MITSUA = calculate_clip(clip, clip_processor, prompt, image_MITSUA)\n",
        "    clip_score_SD21 = calculate_clip(clip, clip_processor, prompt, image_SD21)\n",
        "    clip_score_JUGGXL = calculate_clip(clip, clip_processor, prompt, image_JUGGXL)\n",
        "    clip_score_DALLE2 = calculate_clip(clip, clip_processor, prompt, image_DALLE2)\n",
        "    clip_score_DREAM = calculate_clip(clip, clip_processor, prompt, image_DREAM)\n",
        "    clip_score_LORA = calculate_clip(clip, clip_processor, prompt, image_LORA)\n",
        "    clip_score_TI = calculate_clip(clip, clip_processor, prompt, image_TI)\n",
        "    fid_score_MITSUA = calculate_fid(fid_model, image_MITSUA, image_og)\n",
        "    fid_score_SD21 = calculate_fid(fid_model, image_SD21, image_og)\n",
        "    fid_score_JUGGXL = calculate_fid(fid_model, image_JUGGXL, image_og)\n",
        "    fid_score_DALLE2 = calculate_fid(fid_model, image_DALLE2, image_og)\n",
        "    fid_score_DREAM = calculate_fid(fid_model, image_DREAM, image_og)\n",
        "    fid_score_LORA = calculate_fid(fid_model, image_LORA, image_og)\n",
        "    fid_score_TI = calculate_fid(fid_model, image_TI, image_og)\n",
        "\n",
        "    base_dict = {\n",
        "        \"Category\": cat['name'],\n",
        "        \"Original_CLIP\": clip_score_og,\n",
        "        \"MITSUA_CLIP\": clip_score_MITSUA,\n",
        "        \"MITSUA_FID\": fid_score_MITSUA,\n",
        "        \"SD_CLIP\": clip_score_SD21,\n",
        "        \"SD_FID\": fid_score_SD21,\n",
        "        \"JUGGXL_CLIP\": clip_score_JUGGXL,\n",
        "        \"JUGGXL_FID\": fid_score_JUGGXL,\n",
        "        \"DALLE2_CLIP\": clip_score_DALLE2,\n",
        "        \"DALLE2_FID\": fid_score_DALLE2,\n",
        "        }\n",
        "\n",
        "    fine_dict = {\n",
        "        \"Category\": cat['name'],\n",
        "        \"DREAM_CLIP\": clip_score_DREAM,\n",
        "        \"DREAM_FID\": fid_score_DREAM,\n",
        "        \"LORA_CLIP\": clip_score_LORA,\n",
        "        \"LORA_FID\": fid_score_LORA,\n",
        "        \"TI_CLIP\": clip_score_TI,\n",
        "        \"TI_FID\": fid_score_TI,\n",
        "        }\n",
        "\n",
        "    row_base.append(base_dict)\n",
        "    row_fine.append(fine_dict)\n",
        "\n",
        "    print(base_dict)\n",
        "    print(fine_dict)"
      ],
      "metadata": {
        "id": "wBvdbq7ibZij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base = pd.DataFrame(row_base)\n",
        "df_fine = pd.DataFrame(row_fine)\n",
        "df_base.to_csv(baseline_scores_directory, index=False)\n",
        "df_fine.to_csv(finetuned_scores_directory, index=False)"
      ],
      "metadata": {
        "id": "TfKltOkRbkz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}